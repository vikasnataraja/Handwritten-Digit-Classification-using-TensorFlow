{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Tutorial\n",
    "\n",
    "Build a convolutional neural network with Keras.\n",
    "\n",
    "This example shows how to build a convolutional neural network classifier to classify digits 0-9 in the MNIST dataset.\n",
    "\n",
    "**Author: Vikas Nataraja**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Overview\n",
    "\n",
    "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. \n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The goal of this tutorial is to show you how a convolutional neural network (CNN) functions by walking you through the steps involved in building it, testing it, and deploying it. In this example, we will try to train a CNN so that it learns how to identify digits. So, given an image of a digit (0 - 9), the CNN should tell us what digit is displayed in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# future is imported to allow the use of different versions of Python\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Force use of CPUs instead of GPUs\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "# Keras is a deep learning that is used to build the neural network\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the dataset \n",
    "\n",
    "* Training images are loaded into `train_images` as numpy arrays, corresponding labels (ground truth) are read into another numpy array called `train_labels`\n",
    "* A similar procedure is followed for test images.\n",
    "* The arrays are cast to 32 bit float because Keras takes in float images\n",
    "* We also normalize the pixels so that all the input images always have pixel values between 0 - 1.\n",
    "\n",
    "* `train_images` will be a 3D array - (num_of_images, height, width)\n",
    "* `train_labels` will be a 1D array of 0-9 because we are trying to predict digits 0-9. So the labels are solutions/ground truth to the coresponding `train_images`\n",
    "* `test_images` will be a 3D array - (num_of_images, height, width)\n",
    "* `test_labels` will be a 1D array of 0-9 because we are trying to predict digits 0-9. So the labels are solutions/ground truth to the corresponding `test_labels`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "num_classes = 10           # we have 10 digits so we need 10 classes\n",
    "\n",
    "train_images = np.float32(train_images)/255. # normalize pixel values\n",
    "train_images = np.expand_dims(train_images, -1) # add a channel dimension as this is what Keras expects\n",
    "test_images = np.float32(test_images)/255.  \n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels  = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of training images: ',train_images.shape[0])\n",
    "print('Each training image is of size: ',train_images.shape[1:])\n",
    "print('Number of training labels: ',train_labels.shape[0],'\\n')\n",
    "print('Number of test images: ',test_images.shape[0])\n",
    "print('Each test image is of size: ',test_images.shape[1:])\n",
    "print('Number of test labels: ',test_images.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the dataset - what does the MNIST dataset look like?\n",
    "\n",
    "* Here, we visualize the training set. Each time this cell block is run, random images from the training set will be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    # show random images from the dataset\n",
    "    random_range = randint(0, train_images.shape[0]-1)\n",
    "    img = train_images[random_range]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title('Ground truth label = {}'.format(np.argmax(train_labels[random_range])))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model directory\n",
    "\n",
    "This is where the entire model will be saved on your computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# CHANGE THIS DIRECTORY TO ANY DIRECTORY ON YOUR SYSTEM!!!\n",
    "# This is where the model will be saved after it is run\n",
    "#########################################################\n",
    "model_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "These are the parameters that can be tuned depending on how training goes. For example, \n",
    "\n",
    "    * If the model is too slow to train, decrease the batch size.\n",
    "    * If the loss is still high after training, increase the number of steps\n",
    "    * If the model is learning too slowly or is not converging faster, increase the learning rate.\n",
    "\n",
    "        \n",
    "**Batch size** \n",
    "- The number of images to be taken and trained before updating the weights.\n",
    "- This is done to reduce the memory consumption. Instead of training all images at the same time, we do it batch-by-batch.\n",
    "- Batch sizes are usually in powers of 2 e.g 16, 32, 64, 128 ...\n",
    "- For example if your total number of training images = 2000 and batch size is 128 then we get 15 full batches and the final batch will have the remaining images.\n",
    "- Higher batch size almost always gives better accuracies but will be computationally slow\n",
    "\n",
    "**Learning rate**\n",
    "- It is a number between 0 and 1\n",
    "- Dictates how fast your optimization moves. A popular optimization algorithm is gradient descent.\n",
    "- Learning rates are usually set in tenths like 0.1, 0.01 etc,. It is a good idea to start with a very low value and gradually increase\n",
    "\n",
    "**Number of epochs**\n",
    "- 1 epoch = the model has seen one full pass of the entire training set.\n",
    "- Since we use batches, 1 epoch will be competed after (dataset_size/batch_size) steps\n",
    "- Generally speaking, it is common to train for 100,000 or even 500,000 epochs. For this example we choose a small number - 2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the hyperparameters\n",
    "Feel free to play around with some of these \"hyperparameters\" which are the knobs you turn to affect performance. For instance, you could modify the `batch_size` to be 8 instead of 16.\n",
    "\n",
    "You could also run the entire model as is first and then reset, come back here and change something, run the model again to see what changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define architecture details\n",
    "input_shape = (28, 28, 1)     # because our images are 28 x 28 pixels across\n",
    "num_filters = [16, 32, 64] # filters for convolution => it's usually a good idea to double the number of filters in each step\n",
    "kernel_size = (3, 3)       # this is the convolution kernel\n",
    "num_epochs  = 10         # number of epochs to train for\n",
    "learning_rate = 0.001      # learning rate for the model weights. recommended to start with a low number like 0.0001\n",
    "batch_size = 16           # batch size of the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the layers in the network\n",
    "\n",
    "* The convolutional layer, max pooling layer, fully connected layer are all defined here.\n",
    "* This is essentially the bulk of the work in creating your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "\n",
    "def model_architecture(input_shape:tuple, num_filters:list, kernel_size:tuple, num_classes:int):\n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(num_filters[0], kernel_size=kernel_size, activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(num_filters[1], kernel_size=kernel_size, activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(num_filters[2], kernel_size=kernel_size, activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(100, activation=\"relu\"),\n",
    "        Dense(num_classes, activation=\"softmax\"), # we want probability as the output\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train the model!\n",
    "\n",
    "* This takes time. Depending on the dataset, the network intricacies and the epochs, training time could take anywhere between seconds to days or even weeks.\n",
    "* For example, training ChatGPT took several months\n",
    "* Often in atmospheric science, we train models on GPUs on supercomputers which can exponentially increase the speed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = model_architecture(input_shape, num_filters, kernel_size, num_classes)\n",
    "\n",
    "# callbacks to the model\n",
    "# 1. stop the model early if it is not learning anything\n",
    "# 2. save the model (checkpoint) only if the loss has improved\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=50, verbose=1),\n",
    "             keras.callbacks.ModelCheckpoint(filepath='cnn_model.h5', monitor=\"val_loss\", save_best_only=True, verbose=1)]\n",
    "\n",
    "# our cost function or loss function is cross-entropy which is probabalistic\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# # fit the model to the dataset X: train_images, y: train_labels\n",
    "history = model.fit(train_images, train_labels, \n",
    "          batch_size=batch_size, epochs=num_epochs, \n",
    "          validation_split=0.1, verbose=1,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze how the training went\n",
    "\n",
    "Training and validation loss should be close to each other. \n",
    "\n",
    "- If training loss is low, but validation loss is much higher, that means the model \"overfitted\"\n",
    "    - That means the model probably memorized the training data and when confronted with a new, unseen image, did not know how to respond\n",
    "- If training loss is low, and validation loss is also low, that means the model did a good job\n",
    "- If both losses are high, that means the model did not learn anything and \"underfitted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# first plot will be of accuracies\n",
    "ax[0].plot(history.history['accuracy'], color='blue', label='training')\n",
    "ax[0].plot(history.history['val_accuracy'], color='orange', label='validation')\n",
    "ax[0].set_title('Model Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend()\n",
    "\n",
    "# second plot will be of the errors\n",
    "ax[1].plot(history.history['loss'], color='blue', label='training')\n",
    "ax[1].plot(history.history['val_loss'], color='orange', label='validation')\n",
    "ax[1].set_title('Model Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['training', 'validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the trained model on test set\n",
    "\n",
    "Now that the model has been trained, you can test it on new images i.e your test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict the images class\n",
    "predictions = model.predict(test_images, verbose=0)\n",
    "\n",
    "# Display\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(test_images[i], cmap='gray')\n",
    "    plt.title('Predicted label = {}\\nConfidence = {:0.2f}'.format(np.argmax(predictions[i]), np.max(predictions[i])), pad=5)\n",
    "    plt.axis('off')\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a picture and test your CNN!\n",
    "\n",
    "Let's see if the model can recognize a live image. \n",
    "\n",
    "1. Draw a single digit, take a picture of it and store it somewhere on your computer (must be a png or jpg file)\n",
    "2. Update `filepath` to that image (full path required)\n",
    "3. Call the function below `test_real_digit(filepath)` to see what the model predicts!\n",
    "\n",
    "\n",
    "NOTE: You might need to install the package pillow using this command: `conda install -c anaconda pillow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"some/file/path/here/\" # can be jpg or png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After updating the filepath in the above cell, run the cell below to test the model for your image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_real_digit(filepath, model):\n",
    "    try:\n",
    "        from PIL import Image\n",
    "        import PIL.ImageOps \n",
    "    except ModuleNotFoundError:\n",
    "        print(\"<IMPORT ERROR>: Please install the `pillow` package to proceed. Use `conda install -c anaconda pillow`\")\n",
    "        \n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize((28, 28), Image.Resampling.LANCZOS) # resize to 28 x 28\n",
    "    img = img.convert('L') # convert to grayscale\n",
    "    img = PIL.ImageOps.invert(img) # invert image so the digit is white, background is black\n",
    "    img = np.expand_dims(img, -1) # add extra dimension for Keras\n",
    "    img = np.expand_dims(img, 0)  # add extra dimension for faking batch size\n",
    "    img = img.astype('float')/img.max() # normalize it like we did during training\n",
    "    prediction = model.predict(img, verbose=0)[0]\n",
    "    return img, prediction\n",
    "\n",
    "im, test_pred = test_real_digit(filepath, model)\n",
    "\n",
    "# Visualize it\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.imshow(im[0, :, :, 0], cmap='gray')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Predicted label = {}\\nConfidence = {:0.2f}'.format(np.argmax(test_pred), np.max(test_pred)), pad=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
